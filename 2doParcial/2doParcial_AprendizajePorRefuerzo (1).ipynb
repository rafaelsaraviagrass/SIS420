{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ConnectFourBoard():\n",
        "    def __init__(self, rows=6, cols=7):\n",
        "        \"\"\"\n",
        "        Tablero de 4 en raya (Connect Four)\n",
        "        Por defecto: 6 filas x 7 columnas\n",
        "        \"\"\"\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.state = np.zeros((rows, cols), dtype=int)\n",
        "\n",
        "    def valid_moves(self):\n",
        "        \"\"\"Devuelve las columnas donde se puede hacer un movimiento válido\"\"\"\n",
        "        return [col for col in range(self.cols) if self.state[0, col] == 0]\n",
        "\n",
        "    def update(self, symbol, col):\n",
        "        \"\"\"\n",
        "        Coloca una ficha en la columna especificada\n",
        "        La ficha cae hasta la posición más baja disponible\n",
        "        \"\"\"\n",
        "        if col not in self.valid_moves():\n",
        "            raise ValueError(f\"Movimiento ilegal en columna {col}!\")\n",
        "\n",
        "        # Encontrar la fila más baja disponible en la columna\n",
        "        for row in range(self.rows - 1, -1, -1):\n",
        "            if self.state[row, col] == 0:\n",
        "                self.state[row, col] = symbol\n",
        "                return row, col\n",
        "\n",
        "        raise ValueError(f\"Columna {col} está llena!\")\n",
        "\n",
        "    def is_game_over(self):\n",
        "        \"\"\"\n",
        "        Verifica si el juego ha terminado\n",
        "        Retorna: 1 si gana jugador 1, -1 si gana jugador 2, 0 empate, None si continúa\n",
        "        \"\"\"\n",
        "        # Comprobar victorias horizontales\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.cols - 3):\n",
        "                window = self.state[row, col:col+4]\n",
        "                if np.sum(window) == 4:\n",
        "                    return 1\n",
        "                elif np.sum(window) == -4:\n",
        "                    return -1\n",
        "\n",
        "        # Comprobar victorias verticales\n",
        "        for row in range(self.rows - 3):\n",
        "            for col in range(self.cols):\n",
        "                window = self.state[row:row+4, col]\n",
        "                if np.sum(window) == 4:\n",
        "                    return 1\n",
        "                elif np.sum(window) == -4:\n",
        "                    return -1\n",
        "\n",
        "        # Comprobar diagonales positivas (/)\n",
        "        for row in range(self.rows - 3):\n",
        "            for col in range(self.cols - 3):\n",
        "                window = [self.state[row+i, col+i] for i in range(4)]\n",
        "                if sum(window) == 4:\n",
        "                    return 1\n",
        "                elif sum(window) == -4:\n",
        "                    return -1\n",
        "\n",
        "        # Comprobar diagonales negativas (\\)\n",
        "        for row in range(3, self.rows):\n",
        "            for col in range(self.cols - 3):\n",
        "                window = [self.state[row-i, col+i] for i in range(4)]\n",
        "                if sum(window) == 4:\n",
        "                    return 1\n",
        "                elif sum(window) == -4:\n",
        "                    return -1\n",
        "\n",
        "        # Verificar empate (tablero lleno)\n",
        "        if len(self.valid_moves()) == 0:\n",
        "            return 0\n",
        "\n",
        "        # El juego continúa\n",
        "        return None\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reinicia el tablero\"\"\"\n",
        "        self.state = np.zeros((self.rows, self.cols), dtype=int)\n",
        "\n",
        "    def display(self):\n",
        "        \"\"\"Muestra el tablero de forma visual\"\"\"\n",
        "        print(\"\\n\" + \"=\"*29)\n",
        "        print(\"  0   1   2   3   4   5   6\")\n",
        "        print(\"=\"*29)\n",
        "        for row in self.state:\n",
        "            print(\"| \", end=\"\")\n",
        "            for cell in row:\n",
        "                if cell == 1:\n",
        "                    print(\"X\", end=\" | \")\n",
        "                elif cell == -1:\n",
        "                    print(\"O\", end=\" | \")\n",
        "                else:\n",
        "                    print(\" \", end=\" | \")\n",
        "            print()\n",
        "        print(\"=\"*29)\n",
        "\n",
        "class ConnectFourGame():\n",
        "    def __init__(self, player1, player2):\n",
        "        \"\"\"Inicializa el juego con dos jugadores\"\"\"\n",
        "        player1.symbol = 1\n",
        "        player2.symbol = -1\n",
        "        self.players = [player1, player2]\n",
        "        self.board = ConnectFourBoard()\n",
        "\n",
        "    def selfplay(self, rounds=100):\n",
        "        \"\"\"Ejecuta múltiples partidas de auto-juego para entrenamiento\"\"\"\n",
        "        wins = [0, 0, 0]  # [jugador1, jugador2, empates]\n",
        "\n",
        "        for i in tqdm(range(1, rounds + 1), desc=\"Entrenando agente\"):\n",
        "            self.board.reset()\n",
        "            for player in self.players:\n",
        "                player.reset()\n",
        "\n",
        "            game_over = False\n",
        "            while not game_over:\n",
        "                for player_idx, player in enumerate(self.players):\n",
        "                    if len(self.board.valid_moves()) == 0:\n",
        "                        game_over = True\n",
        "                        break\n",
        "\n",
        "                    try:\n",
        "                        action = player.move(self.board)\n",
        "                        self.board.update(player.symbol, action)\n",
        "\n",
        "                        # Actualizar estados de ambos jugadores\n",
        "                        for p in self.players:\n",
        "                            p.update(self.board)\n",
        "\n",
        "                        # Verificar si el juego terminó\n",
        "                        game_result = self.board.is_game_over()\n",
        "                        if game_result is not None:\n",
        "                            game_over = True\n",
        "                            break\n",
        "\n",
        "                    except ValueError:\n",
        "                        # Movimiento inválido, el jugador pierde\n",
        "                        game_over = True\n",
        "                        break\n",
        "\n",
        "            # Asignar recompensas\n",
        "            self.reward()\n",
        "\n",
        "            # Contar victorias\n",
        "            result = self.board.is_game_over()\n",
        "            if result == 1:\n",
        "                wins[0] += 1\n",
        "            elif result == -1:\n",
        "                wins[1] += 1\n",
        "            else:\n",
        "                wins[2] += 1\n",
        "\n",
        "        return wins\n",
        "\n",
        "    def reward(self):\n",
        "        \"\"\"Asigna recompensas a los jugadores basado en el resultado\"\"\"\n",
        "        winner = self.board.is_game_over()\n",
        "\n",
        "        if winner == 0:  # Empate\n",
        "            for player in self.players:\n",
        "                player.reward(0.5)\n",
        "        else:  # Hay un ganador\n",
        "            for player in self.players:\n",
        "                if winner == player.symbol:\n",
        "                    player.reward(1.0)  # Victoria\n",
        "                else:\n",
        "                    player.reward(0.0)  # Derrota\n",
        "\n",
        "    def play_human_vs_agent(self, human_symbol=1):\n",
        "        \"\"\"Permite a un humano jugar contra el agente entrenado\"\"\"\n",
        "        self.board.reset()\n",
        "\n",
        "        if human_symbol == 1:\n",
        "            human_player = self.players[0]\n",
        "            agent_player = self.players[1]\n",
        "        else:\n",
        "            human_player = self.players[1]\n",
        "            agent_player = self.players[0]\n",
        "\n",
        "        print(\"¡Juego de 4 en Raya!\")\n",
        "        print(\"Tú eres las fichas 'X' si juegas como jugador 1, 'O' si juegas como jugador 2\")\n",
        "        self.board.display()\n",
        "\n",
        "        game_over = False\n",
        "        current_player = 0  # 0 para jugador 1, 1 para jugador 2\n",
        "\n",
        "        while not game_over:\n",
        "            if (current_player == 0 and human_symbol == 1) or (current_player == 1 and human_symbol == -1):\n",
        "                # Turno del humano\n",
        "                valid_cols = self.board.valid_moves()\n",
        "                print(f\"Columnas válidas: {valid_cols}\")\n",
        "\n",
        "                try:\n",
        "                    col = int(input(\"Elige una columna (0-6): \"))\n",
        "                    if col not in valid_cols:\n",
        "                        print(\"¡Movimiento inválido! Intenta de nuevo.\")\n",
        "                        continue\n",
        "\n",
        "                    self.board.update(human_player.symbol, col)\n",
        "\n",
        "                except (ValueError, IndexError):\n",
        "                    print(\"¡Entrada inválida! Intenta de nuevo.\")\n",
        "                    continue\n",
        "            else:\n",
        "                # Turno del agente\n",
        "                print(\"Turno del agente...\")\n",
        "                col = agent_player.move(self.board, explore=False)  # Sin exploración\n",
        "                self.board.update(agent_player.symbol, col)\n",
        "                print(f\"El agente eligió la columna {col}\")\n",
        "\n",
        "            self.board.display()\n",
        "\n",
        "            # Verificar fin del juego\n",
        "            result = self.board.is_game_over()\n",
        "            if result is not None:\n",
        "                if result == human_symbol:\n",
        "                    print(\"¡Felicidades! ¡Has ganado!\")\n",
        "                elif result == -human_symbol:\n",
        "                    print(\"El agente ha ganado. ¡Mejor suerte la próxima vez!\")\n",
        "                else:\n",
        "                    print(\"¡Empate!\")\n",
        "                game_over = True\n",
        "\n",
        "            # Cambiar turno\n",
        "            current_player = 1 - current_player\n",
        "\n",
        "class ConnectFourAgent():\n",
        "    def __init__(self, alpha=0.3, prob_exp=0.3):\n",
        "        \"\"\"\n",
        "        Agente de aprendizaje por refuerzo para 4 en raya\n",
        "\n",
        "        Args:\n",
        "            alpha: tasa de aprendizaje (learning rate)\n",
        "            prob_exp: probabilidad de exploración\n",
        "        \"\"\"\n",
        "        self.value_function = {}  # Tabla estado -> valor\n",
        "        self.alpha = alpha        # Tasa de aprendizaje\n",
        "        self.positions = []       # Estados visitados en la partida actual\n",
        "        self.prob_exp = prob_exp  # Probabilidad de exploración\n",
        "        self.symbol = None        # Se asigna durante el juego\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reinicia el historial de posiciones para una nueva partida\"\"\"\n",
        "        self.positions = []\n",
        "\n",
        "    def move(self, board, explore=True):\n",
        "        \"\"\"\n",
        "        Decide el próximo movimiento\n",
        "\n",
        "        Args:\n",
        "            board: estado actual del tablero\n",
        "            explore: si True, permite exploración; si False, solo explotación\n",
        "        \"\"\"\n",
        "        valid_moves = board.valid_moves()\n",
        "\n",
        "        if not valid_moves:\n",
        "            raise ValueError(\"No hay movimientos válidos disponibles\")\n",
        "\n",
        "        # Exploración: movimiento aleatorio\n",
        "        if explore and np.random.uniform(0, 1) < self.prob_exp:\n",
        "            return np.random.choice(valid_moves)\n",
        "\n",
        "        # Explotación: elegir el mejor movimiento conocido\n",
        "        max_value = -1000\n",
        "        best_col = valid_moves[0]  # Por defecto, el primer movimiento válido\n",
        "\n",
        "        for col in valid_moves:\n",
        "            # Simular el movimiento\n",
        "            next_board = board.state.copy()\n",
        "\n",
        "            # Encontrar dónde caería la ficha\n",
        "            for row in range(board.rows - 1, -1, -1):\n",
        "                if next_board[row, col] == 0:\n",
        "                    next_board[row, col] = self.symbol\n",
        "                    break\n",
        "\n",
        "            # Convertir estado a string para búsqueda en tabla\n",
        "            next_state = str(next_board.flatten())\n",
        "            value = self.value_function.get(next_state, 0)\n",
        "\n",
        "            if value > max_value:\n",
        "                max_value = value\n",
        "                best_col = col\n",
        "\n",
        "        return best_col\n",
        "\n",
        "    def update(self, board):\n",
        "        \"\"\"Actualiza el historial de posiciones visitadas\"\"\"\n",
        "        state_str = str(board.state.flatten())\n",
        "        self.positions.append(state_str)\n",
        "\n",
        "    def reward(self, reward):\n",
        "        \"\"\"\n",
        "        Actualiza la función de valor usando la recompensa recibida\n",
        "        Implementa Temporal Difference Learning\n",
        "        \"\"\"\n",
        "        for position in reversed(self.positions):\n",
        "            if position not in self.value_function:\n",
        "                self.value_function[position] = 0\n",
        "\n",
        "            # Actualización TD: V(s) = V(s) + α * (reward - V(s))\n",
        "            self.value_function[position] += self.alpha * (reward - self.value_function[position])\n",
        "            reward = self.value_function[position]\n",
        "\n",
        "    def save_agent(self, filename):\n",
        "        \"\"\"Guarda la función de valor del agente\"\"\"\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(self.value_function, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        print(f\"Agente guardado en {filename}\")\n",
        "\n",
        "    def load_agent(self, filename):\n",
        "        \"\"\"Carga la función de valor del agente\"\"\"\n",
        "        try:\n",
        "            with open(filename, 'rb') as f:\n",
        "                self.value_function = pickle.load(f)\n",
        "            print(f\"Agente cargado desde {filename}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Archivo {filename} no encontrado. Iniciando con agente nuevo.\")\n",
        "\n",
        "# =============================================================================\n",
        "# ENTRENAMIENTO DEL AGENTE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Iniciando entrenamiento del agente de 4 en raya...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Crear dos agentes\n",
        "agent1 = ConnectFourAgent(alpha=0.3, prob_exp=0.4)  # Más exploración\n",
        "agent2 = ConnectFourAgent(alpha=0.3, prob_exp=0.2)  # Menos exploración\n",
        "\n",
        "# Crear el juego\n",
        "game = ConnectFourGame(agent1, agent2)\n",
        "\n",
        "# Entrenar con diferentes números de partidas\n",
        "training_rounds = [10000, 50000, 100000]\n",
        "results = []\n",
        "\n",
        "for rounds in training_rounds:\n",
        "    print(f\"\\nEntrenando con {rounds} partidas...\")\n",
        "    wins = game.selfplay(rounds)\n",
        "\n",
        "    win_rate_1 = wins[0] / rounds * 100\n",
        "    win_rate_2 = wins[1] / rounds * 100\n",
        "    draw_rate = wins[2] / rounds * 100\n",
        "\n",
        "    print(f\"Resultados después de {rounds} partidas:\")\n",
        "    print(f\"  Agente 1 (X): {wins[0]} victorias ({win_rate_1:.1f}%)\")\n",
        "    print(f\"  Agente 2 (O): {wins[1]} victorias ({win_rate_2:.1f}%)\")\n",
        "    print(f\"  Empates: {wins[2]} ({draw_rate:.1f}%)\")\n",
        "\n",
        "    results.append({\n",
        "        'rounds': rounds,\n",
        "        'agent1_wins': wins[0],\n",
        "        'agent2_wins': wins[1],\n",
        "        'draws': wins[2],\n",
        "        'states_learned': len(agent1.value_function)\n",
        "    })\n",
        "\n",
        "# =============================================================================\n",
        "# ANÁLISIS DE RESULTADOS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ANÁLISIS DE RESULTADOS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Mostrar evolución del aprendizaje\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nEvolución del aprendizaje:\")\n",
        "print(df_results)\n",
        "\n",
        "# Función de valor aprendida\n",
        "print(f\"\\nEstados aprendidos por el agente: {len(agent1.value_function)}\")\n",
        "\n",
        "# Mostrar los mejores estados según el agente\n",
        "value_function_sorted = sorted(agent1.value_function.items(),\n",
        "                              key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nTop 10 mejores estados según el agente:\")\n",
        "for i, (state, value) in enumerate(value_function_sorted[:10]):\n",
        "    print(f\"{i+1}. Valor: {value:.4f}\")\n",
        "\n",
        "# Guardar el agente entrenado\n",
        "agent1.save_agent('agente_conecta4.pickle')\n",
        "\n",
        "# =============================================================================\n",
        "# VISUALIZACIÓN DE RESULTADOS\n",
        "# =============================================================================\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Gráfico 1: Evolución de victorias\n",
        "rounds_list = df_results['rounds'].tolist()\n",
        "ax1.plot(rounds_list, df_results['agent1_wins'], 'b-o', label='Agente 1', linewidth=2)\n",
        "ax1.plot(rounds_list, df_results['agent2_wins'], 'r-o', label='Agente 2', linewidth=2)\n",
        "ax1.plot(rounds_list, df_results['draws'], 'g-o', label='Empates', linewidth=2)\n",
        "ax1.set_xlabel('Partidas de entrenamiento')\n",
        "ax1.set_ylabel('Número de victorias')\n",
        "ax1.set_title('Evolución de Victorias durante el Entrenamiento')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Porcentajes de victoria\n",
        "win_rates_1 = [wins/rounds*100 for wins, rounds in zip(df_results['agent1_wins'], df_results['rounds'])]\n",
        "win_rates_2 = [wins/rounds*100 for wins, rounds in zip(df_results['agent2_wins'], df_results['rounds'])]\n",
        "draw_rates = [draws/rounds*100 for draws, rounds in zip(df_results['draws'], df_results['rounds'])]\n",
        "\n",
        "ax2.plot(rounds_list, win_rates_1, 'b-o', label='Agente 1', linewidth=2)\n",
        "ax2.plot(rounds_list, win_rates_2, 'r-o', label='Agente 2', linewidth=2)\n",
        "ax2.plot(rounds_list, draw_rates, 'g-o', label='Empates', linewidth=2)\n",
        "ax2.set_xlabel('Partidas de entrenamiento')\n",
        "ax2.set_ylabel('Porcentaje de victorias (%)')\n",
        "ax2.set_title('Tasa de Victoria durante el Entrenamiento')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 3: Estados aprendidos\n",
        "ax3.plot(rounds_list, df_results['states_learned'], 'purple', marker='o', linewidth=2)\n",
        "ax3.set_xlabel('Partidas de entrenamiento')\n",
        "ax3.set_ylabel('Número de estados aprendidos')\n",
        "ax3.set_title('Crecimiento del Conocimiento del Agente')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 4: Distribución de valores en la función de valor\n",
        "values = list(agent1.value_function.values())\n",
        "ax4.hist(values, bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
        "ax4.set_xlabel('Valor del estado')\n",
        "ax4.set_ylabel('Frecuencia')\n",
        "ax4.set_title('Distribución de Valores en la Función de Valor')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ENTRENAMIENTO COMPLETADO\")\n",
        "print(\"=\"*50)\n",
        "print(\"El agente ha sido entrenado y guardado como 'agente_conecta4.pickle'\")\n",
        "print(\"Puedes usar este agente para jugar contra él o continuar el entrenamiento.\")\n",
        "\n",
        "# =============================================================================\n",
        "# FUNCIÓN PARA JUGAR CONTRA EL AGENTE (OPCIONAL)\n",
        "# =============================================================================\n",
        "\n",
        "def jugar_contra_agente():\n",
        "    \"\"\"Función para jugar una partida contra el agente entrenado\"\"\"\n",
        "    print(\"\\n¿Quieres jugar una partida contra el agente? (s/n): \", end=\"\")\n",
        "    respuesta = input().lower()\n",
        "\n",
        "    if respuesta == 's':\n",
        "        # Crear nuevos agentes para el juego\n",
        "        agente_humano = ConnectFourAgent(prob_exp=0)  # Sin exploración para el \"humano\"\n",
        "        agente_ia = ConnectFourAgent(prob_exp=0)      # Sin exploración para juego serio\n",
        "        agente_ia.value_function = agent1.value_function.copy()  # Copiar conocimiento\n",
        "\n",
        "        juego_vs_humano = ConnectFourGame(agente_humano, agente_ia)\n",
        "        juego_vs_humano.play_human_vs_agent(human_symbol=1)\n",
        "\n",
        "# Llamar a la función de juego si se desea\n",
        "# jugar_contra_agente()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T84ME3vGLnxd",
        "outputId": "788c15ac-bb7d-4926-c909-2ec59641edc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando entrenamiento del agente de 4 en raya...\n",
            "==================================================\n",
            "\n",
            "Entrenando con 10000 partidas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Entrenando agente: 100%|██████████| 10000/10000 [04:41<00:00, 35.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados después de 10000 partidas:\n",
            "  Agente 1 (X): 6575 victorias (65.8%)\n",
            "  Agente 2 (O): 3362 victorias (33.6%)\n",
            "  Empates: 63 (0.6%)\n",
            "\n",
            "Entrenando con 50000 partidas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Entrenando agente:  29%|██▉       | 14383/50000 [06:13<16:16, 36.46it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}